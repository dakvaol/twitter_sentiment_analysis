{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter datasethuge_train_tweets.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'encoding': 'utf-8', 'confidence': 0.99, 'language': ''}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Optional module\n",
    "#Checks the encoding of inputed data data\n",
    "import chardet\n",
    "with open(input('Enter dataset '), 'rb') as rawdata:\n",
    "    result = chardet.detect(rawdata.read(1000000))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename of training sethuge_train_tweets.csv\n",
      "Column containing labels of training datatarget\n",
      "Column containing tweets of training datatext \n",
      "['target' 'id' 'date' 'flag' 'user' 'text ']\n"
     ]
    }
   ],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score\n",
    "\n",
    "#Importing data\n",
    "training_set = input('Filename of training set ')\n",
    "train_label = input('Column containing labels of training data ')\n",
    "train_tweets = input('Column containing tweets of training data ')\n",
    "train = pd.read_csv(training_set)\n",
    "\n",
    "#Prints columns of imported dataset\n",
    "columns = train.columns.values\n",
    "print(columns)\n",
    "#train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800000\n",
      "800000\n"
     ]
    }
   ],
   "source": [
    "positive=[]\n",
    "negative=[]\n",
    "dontknow=[]\n",
    "i=0\n",
    "while i<len(train):\n",
    "    if train['target'][i] == 0:\n",
    "        positive.append(train['target'][i])\n",
    "        i+=1\n",
    "    elif train['target'][i] == 1:\n",
    "        negative.append(train['target'][i])\n",
    "        i+=1\n",
    "    else: \n",
    "        dontknow.append('dont work')\n",
    "        i+=1\n",
    "        \n",
    "print(len(positive))\n",
    "print(len(negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target          id                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                              text   \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Optional module\n",
    "#Splits multinominal data into binominal data\n",
    "mean = train[train_label].mean()\n",
    "binary_target = []\n",
    "\n",
    "for element in train[train_label]:\n",
    "    if element >= mean:\n",
    "        binary_target.append(1)\n",
    "    elif element < mean:\n",
    "        binary_target.append(0)\n",
    "train[train_label] = binary_target\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(tweet):     \n",
    "    #Tokenization\n",
    "    def form_sentence(tweet):\n",
    "        tweet_blob = TextBlob(tweet)\n",
    "        return ' '.join(tweet_blob.words)\n",
    "    formed_tweet = form_sentence(tweet)\n",
    "    #Removes words and symbols with little to no \n",
    "    #sentimental value\n",
    "    def clean_tweets(tweet):\n",
    "        tweet_split = [wrd for wrd in tweet.split()]\n",
    "        clean_wrds = [s for s in tweet_split if re.match(r'[^\\W\\d]*$', s)]\n",
    "        clean_s = ' '.join(clean_wrds)\n",
    "        clean = [word for word in clean_s.split() if word.lower() not in stopwords.words('english')]\n",
    "        return clean\n",
    "    clean_tweet = clean_tweets(formed_tweet)\n",
    "    #Normalizes the tweets\n",
    "    #eg.replaces words with same meaning\n",
    "    def normalize(tweets):\n",
    "        lem = WordNetLemmatizer()\n",
    "        normalized_tweet = []\n",
    "        for word in tweets:\n",
    "            normalized_text = lem.lemmatize(word,'v')\n",
    "            normalized_tweet.append(normalized_text)\n",
    "        return normalized_tweet\n",
    "    return normalize(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline for data to go through\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('bow', CountVectorizer(analyzer = preprocessing)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('bow',\n",
       "                 CountVectorizer(analyzer=<function preprocessing at 0x7fb8c2d981f0>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('classifier', MultinomialNB())])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Splits data into test and training datasets\n",
    "tweet_train, tweet_test, label_train, label_test = train_test_split(train[train_tweets], train[train_label], test_size=0.2)\n",
    "pipeline.fit(tweet_train,label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75923125\n",
      "[0 1 1 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "#Predictions of train / test split\n",
    "predictions = pipeline.predict(tweet_test)\n",
    "#print(classification_report(predictions,label_test))\n",
    "print(accuracy_score(predictions, label_test))\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40554408359927413\n"
     ]
    }
   ],
   "source": [
    "#Predictions of another dataset\n",
    "#Pretty horible results\n",
    "new_tweets = pd.read_csv('train_tweets.csv')\n",
    "new_predictions = pipeline.predict(new_tweets['tweet'])\n",
    "print(accuracy_score(new_predictions, new_tweets['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
